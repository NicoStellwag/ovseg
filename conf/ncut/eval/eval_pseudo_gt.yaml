# @package _group_
base_dir: /mnt/hdd/tmp # set equal to the save_dir of the respective ncut/run_offline.py run
res_dir: ${ncut.eval.base_dir}/results
gt_data:
  dataset:
    _target_: datasets.semseg.SemanticSegmentationDataset
    dataset_name: "scannet200"
    data_dir: /mnt/hdd/scannet200_preprocessed
    image_augmentations_path: null
    volume_augmentations_path: null
    label_db_filepath: /mnt/hdd/scannet200_preprocessed/label_database.yaml
    color_mean_std: /mnt/hdd/scannet200_preprocessed/color_mean_std.yaml
    data_percent: 1.0
    mode: ${data.validation_mode}
    ignore_label: ${data.ignore_label}
    num_labels: ${data.num_labels}
    add_raw_coordinates: ${data.add_raw_coordinates}
    add_colors: ${data.add_colors}
    add_normals: ${data.add_normals}
    add_instance: ${data.add_instance}
    cropping: false
    is_tta: false
    crop_min_size: ${data.crop_min_size}
    crop_length: ${data.crop_length}
    filter_out_classes: [0, 2]
    label_offset: 2
  dataloader:
    _target_: torch.utils.data.DataLoader
    batch_size: 1
    shuffle: false
ncut_data:
  dataset:
    _target_: ovseg.datasets.openvocab_semseg.OpenVocabSemanticSegmentationDataset
    dataset_name: "openvocab_scannet200"
    data_dir: /mnt/hdd/scannet200_preprocessed
    ground_truth_dir: ${ncut.eval.base_dir}
    point_instances_file: pointwise_instances.npy
    instance_labels_file: instance_labels.npy
    dim_reduce: ${data.dim_reduce}
    feature_dim_reduction_path: ${data.feature_dim_reduction_path}
    image_augmentations_path: null
    volume_augmentations_path: null
    label_db_filepath: /mnt/hdd/scannet200_preprocessed/label_database.yaml
    color_mean_std: /mnt/hdd/scannet200_preprocessed/color_mean_std.yaml
    data_percent: 1.0
    mode: ${data.validation_mode}
    ignore_label: ${data.ignore_label}
    num_labels: ${data.num_labels}
    add_raw_coordinates: ${data.add_raw_coordinates}
    add_colors: ${data.add_colors}
    add_normals: ${data.add_normals}
    add_instance: ${data.add_instance}
    cropping: false
    is_tta: false
    crop_min_size: ${data.crop_min_size}
    crop_length: ${data.crop_length}
    filter_out_classes: []
    label_offset: 0
  dataloader:
    _target_: torch.utils.data.DataLoader
    batch_size: 1
    shuffle: false

# @package _group_
# based on minimal lseg implementation for easier clip extraction
# https://github.com/krrish94/lseg-minimal
# (follow installation instructions described there)
save_dir: /mnt/hdd/ncut_features/2d/lseg
coords_filename: coords.npy # npy
feats_filename: lseg_feats.npy # npy
visualization_filename: visualization.html # html
feature_dim: 512
model_scale_fac: 0.5 # lseg model cuts size in half
image_batch_size: 16 # inference on how many images at the same time
model:
  weights_path: /mnt/hdd/lseg_weights/lseg_minimal_e200.ckpt
  weights_type: state_dict # alternative: checkpoint
  _target_: lseg.lseg_net.LSegNet
  backbone: clip_vitl16_384
  features: 256
  crop_size: 480
  arch_option: 0
  block_depth: 0
  activation: lrelu
  labels: None
data:
  dataset:
    _target_: ncut.ncut_dataset.NcutScannetDataset
    dataset_dir: /mnt/hdd/scannet
    sensordata_glob_pattern: "*.sens"
    mesh_glob_pattern: "*_vh_clean_2.ply"
    voxel_size: 0.02
    scale_colors_to_depth_resolution: true
    frame_skip: 10
    content:
      - color_images
      - camera_poses
      - color_intrinsics
      - mesh_voxel_coords
      - mesh_original_coords

  dataloader: # overwrite dataset with ds and collate_fn with the identity function to use this
    _target_: torch.utils.data.DataLoader
    batch_size: 1
    # num_workers: 2
    # persistent_workers: True
# @package _group_
save_dir: '/mnt/hdd/ncut_eval_v2'
coords_filename: coords.npy
instances_filename: pointwise_instances.npy
labels_filename: instance_labels.npy
segment_visualization_filename: null
instance_visualization_filename: null
feature_extraction_2d: ???
feature_extraction_3d: ???
eval: ???
use_ds_gt_segmentation: false # if true, aggregate features over ds ground truth instances
use_3d_feats: true
dim_reduce_2d: -1 # -1 for keep full dim
method: spectral_clustering # iterative / spectral_clustering

# spectral clustering
spectral_cluster_method: elbow # kmeans/ gmeans / xmeans / elbow
spectral_filter_instances: false
spectral_kmeans_k: 20
spectral_gmeans_tolerance: -1 # , -1 takes default, we likely want higher
spectral_xmeans_tolerance: -1 # , -1 takes default, we likely want higher

# iterative
affinity_tau: 0.70

max_number_of_instances: 20
min_segment_size: 4
separation_mode: max
max_extent_ratio: 0.8

data:
  dataset:
    _target_: ncut.ncut_datasets.NormalizedCutDataset
    scannet_base_dir: /mnt/hdd/scannet
    scannet_preprocessed_base_dir: /mnt/hdd/scannet200_preprocessed
    mode: train
    segments_base_dir: /mnt/hdd/scannet_segments
    base_dir_3d: /mnt/hdd/ncut_features/3d/csc
    coords_filename_3d: coords.npy
    features_filename_3d: csc_feats.npy
    base_dir_2d: /mnt/hdd/ncut_features/2d/lseg
    coords_filename_2d: coords.npy
    features_filename_2d: lseg_feats.npy
    skip: 1 # should usually be 1, or just delete it
  dataloader:
    _target_: torch.utils.data.DataLoader
    batch_size: 1
    # num_workers: 2
    # persistent_workers: True
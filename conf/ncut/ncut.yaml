# @package _group_
save_dir: '/mnt/hdd/self_training_initial2'
coords_filename: coords.npy
instances_filename: pointwise_instances.npy
labels_filename: instance_labels.npy
segment_visualization_filename: segments.html
instance_visualization_filename: instances.html
feature_extraction_2d: ???
feature_extraction_3d: ???
eval: ???
use_ds_gt_segmentation: false # if true, aggregate features over ds ground truth instances
method: iterative # iterative / spectral_clustering

# spectral clustering
spectral_cluster_method: elbow # kmeans/ gmeans / xmeans / elbow
spectral_kmeans_k: 15
spectral_gmeans_tolerance: -1 # , -1 takes default, we likely want higher
spectral_xmeans_tolerance: -1 # , -1 takes default, we likely want higher

# iterative
affinity_tau: 0.73

max_number_of_instances: 25
min_segment_size: 4
separation_mode: max
max_extent_ratio: 0.8

data:
  dataset:
    _target_: ncut.ncut_datasets.NormalizedCutDataset
    scannet_base_dir: /mnt/hdd/scannet
    scannet_preprocessed_base_dir: /mnt/hdd/scannet200_preprocessed
    mode: val
    segments_base_dir: /mnt/hdd/scannet_segments
    base_dir_3d: /mnt/hdd/ncut_features/3d/csc
    coords_filename_3d: coords.npy
    features_filename_3d: csc_feats.npy
    base_dir_2d: /mnt/hdd/ncut_features/2d/lseg
    coords_filename_2d: coords.npy
    features_filename_2d: lseg_feats.npy
    skip: 1 # should usually be 1, or just delete it
  dataloader:
    _target_: torch.utils.data.DataLoader
    batch_size: 1
    # num_workers: 2
    # persistent_workers: True